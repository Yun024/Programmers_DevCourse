{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-4. 뭉게뭉게 단어구름, Wordcloud\n",
    "- wordcloud를 이용해서 텍스트 구름을 만들어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install wordcloud\n",
    "%pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 구름을 그리기 위해 필요한 라이브러리를 불러와봅시다.\n",
    "\n",
    "# 시각화에 쓰이는 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# 횟수를 기반으로 딕셔너리 생성\n",
    "from collections import Counter\n",
    "\n",
    "# 문장에서 명사를 추출하는 형태소 분석 라이브러리\n",
    "from konlpy.tag import Hannanum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워드클라우드를 만드는 데 사용할 애국가 가사입니다.\n",
    "\n",
    "national_anthem = \"\"\"\n",
    "동해물과 백두산이 마르고 닳도록\n",
    "하느님이 보우하사 우리나라 만세\n",
    "무궁화 삼천리 화려 강산\n",
    "대한 사람 대한으로 길이 보전하세\n",
    "남산 위에 저 소나무 철갑을 두른 듯\n",
    "바람 서리 불변함은 우리 기상일세\n",
    "무궁화 삼천리 화려 강산\n",
    "대한 사람 대한으로 길이 보전하세\n",
    "가을 하늘 공활한데 높고 구름 없이\n",
    "밝은 달은 우리 가슴 일편단심일세\n",
    "무궁화 삼천리 화려 강산\n",
    "대한 사람 대한으로 길이 보전하세\n",
    "이 기상과 이 맘으로 충성을 다하여\n",
    "괴로우나 즐거우나 나라 사랑하세\n",
    "무궁화 삼천리 화려 강산\n",
    "대한 사람 대한으로 길이 보전하세\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hannanum 객체를 생성한 후, .nouns()를 통해 명사를 추출합니다.\n",
    "# 형태소 분석기 객체를 사용해서 주어진 문자열에서 명사를 추출\n",
    "hannanum = Hannanum()\n",
    "nouns = hannanum.nouns(national_anthem)\n",
    "words = [noun for noun in nouns if len(noun) > 1]\n",
    "\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter를 이용해 각 단어의 개수를 세줍니다.\n",
    "\n",
    "counter = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordCloud를 이용해 텍스트 구름을 만들어봅시다.\n",
    "wordcloud = WordCloud(\n",
    "    font_path = \"C:\\Windows\\Fonts\\H2HDRM\",\n",
    "    background_color=\"white\",\n",
    "    width =1000,\n",
    "    height=1000\n",
    ")\n",
    "\n",
    "img = wordcloud.generate_from_frequencies(counter)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-5. 워드클라우드 만들기 - 해시코드 질문 키워드\n",
    "\n",
    "- bs4와 wordcloud를 이용해서 질문 키워드를 보여주는 시각화를 진행해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 User-Agent를 추가해봅시다.\n",
    "user_agent = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pagination이 되어있는 질문 리스트의 제목을 모두 가져와 리스트 questions에 저장해봅시다.\n",
    "# https://hashcode.co.kr/?page={i}\n",
    "# 과도한 요청을 방지하기 위해 0.5초마다 요청을 보내봅시다.\n",
    "questions = []\n",
    "for i in range(1,6):\n",
    "    res = requests.get(f\"https://hashcode.co.kr/?page={i}\", user_agent)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "    \n",
    "    parsed_datas = soup.find_all(\"li\",\"question-list-item\")\n",
    "    \n",
    "    for data in parsed_datas:\n",
    "        questions.append(data.h4.text.strip())\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "print(questions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 구름을 그리기 위해 필요한 라이브러리를 불러와봅시다.\n",
    "\n",
    "# 시각화에 쓰이는 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# 횟수를 기반으로 딕셔너리 생성\n",
    "from collections import Counter\n",
    "\n",
    "# 문장에서 명사를 추출하는 형태소 분석 라이브러리\n",
    "from konlpy.tag import Hannanum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hannanum 객체를 생성한 후, .nouns()를 통해 명사를 추출합니다.\n",
    "words = []\n",
    "hannanum = Hannanum()\n",
    "for question in questions:\n",
    "    nouns = hannanum.nouns(question) # 1번 반복할 때 나온 명사들\n",
    "    words += nouns # 누적해서 나오는 명사들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter를 이용해 각 단어의 개수를 세줍니다.\n",
    "counter = Counter(words)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordCloud를 이용해 텍스트 구름을 만들어봅시다.\n",
    "wordcloud = WordCloud(\n",
    "    font_path=\"C:\\Windows\\Fonts\\H2HDRM\",\n",
    "    background_color=\"white\",\n",
    "    height=1000,\n",
    "    width=1000\n",
    ")\n",
    "\n",
    "img = wordcloud.generate_from_frequencies(counter)\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
