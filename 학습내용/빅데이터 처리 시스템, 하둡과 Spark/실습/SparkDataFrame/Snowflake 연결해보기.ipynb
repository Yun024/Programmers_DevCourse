{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Pyspark DataFrame #5\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowflae 연결 정보\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "user = os.environ.get(\"SNOWFLAKE_USER\")\n",
    "password = os.environ.get(\"SNOWFLAKE_PASS\")\n",
    "account = os.environ.get(\"SNOWFLAKE_ACCOUNT\")\n",
    "jdbc_url = f\"jdbc:snowflake://{account}.snowflakecomputing.com/?warehouse=COMPUTE_WH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- USERID: long (nullable = true)\n",
      " |-- SESSIONID: string (nullable = true)\n",
      " |-- CHANNEL: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_user_session_channel = spark.read \\\n",
    "    .format(\"jdbc\")\\\n",
    "    .option(\"url\",jdbc_url)\\\n",
    "    .option(\"dbtable\",\"dev.raw_data.user_session_channel\")\\\n",
    "    .option(\"user\",user)\\\n",
    "    .option(\"password\",password)\\\n",
    "    .option(\"driver\", \"net.snowflake.client.jdbc.SnowflakeDriver\") \\\n",
    "    .load()\n",
    "\n",
    "df_user_session_channel.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SESSIONID: string (nullable = true)\n",
      " |-- TS: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_session_timestamp = spark.read \\\n",
    "    .format(\"jdbc\")\\\n",
    "    .option(\"url\",jdbc_url)\\\n",
    "    .option(\"dbtable\",\"dev.raw_data.session_timestamp\")\\\n",
    "    .option(\"user\",user)\\\n",
    "    .option(\"password\",password)\\\n",
    "    .option(\"driver\", \"net.snowflake.client.jdbc.SnowflakeDriver\") \\\n",
    "    .load()\n",
    "\n",
    "df_session_timestamp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 몇 개의 파티션을 가지고 있는지 확인\n",
    "df_user_session_channel.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_session_timestamp.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame으로 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- USERID: long (nullable = true)\n",
      " |-- SESSIONID: string (nullable = true)\n",
      " |-- CHANNEL: string (nullable = true)\n",
      " |-- SESSIONID: string (nullable = true)\n",
      " |-- TS: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "join_expr = df_user_session_channel.SESSIONID == df_session_timestamp.SESSIONID\n",
    "session_df = df_user_session_channel.join(df_session_timestamp, join_expr, \"inner\")\n",
    "session_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------+--------------------+--------------------+\n",
      "|USERID|           SESSIONID| CHANNEL|           SESSIONID|                  TS|\n",
      "+------+--------------------+--------+--------------------+--------------------+\n",
      "|   371|5c3a3b139a11689e0...|   Naver|5c3a3b139a11689e0...|2019-05-06 21:33:...|\n",
      "|   654|4afa19649ae378da3...|   Naver|4afa19649ae378da3...|2019-05-10 16:23:...|\n",
      "|   768|87efe7b5fa21d969f...|Facebook|87efe7b5fa21d969f...| 2019-05-25 23:18:00|\n",
      "|   264|0765933456f074d2c...| Youtube|0765933456f074d2c...|2019-05-05 17:55:...|\n",
      "|  1027|a4a1108bbcc329a70...| Organic|a4a1108bbcc329a70...|2019-05-26 14:19:...|\n",
      "+------+--------------------+--------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sessionid가 두개 있어서 에러 발생생\n",
    "session_df = df_user_session_channel.join(df_session_timestamp, join_expr, \"inner\").select(\n",
    "    \"userid\", \"sessionid\", \"channel\", \"ts\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_df = df_user_session_channel.join(df_session_timestamp, join_expr, \"inner\").select(\n",
    "    \"userid\", df_user_session_channel.SESSIONID, \"channel\", \"ts\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|  channel|count|\n",
      "+---------+-----+\n",
      "|  Youtube|17091|\n",
      "|   Google|16982|\n",
      "|    Naver|16921|\n",
      "|  Organic|16904|\n",
      "|Instagram|16831|\n",
      "| Facebook|16791|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel_count_df = session_df.groupby(\"channel\").count().orderBy(\"count\", ascending=False)\n",
    "channel_count_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|  month|mau|\n",
      "+-------+---+\n",
      "|2019-05|281|\n",
      "|2019-06|459|\n",
      "|2019-07|623|\n",
      "|2019-08|662|\n",
      "|2019-09|639|\n",
      "|2019-10|763|\n",
      "|2019-11|721|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## MAU계산하기\n",
    "from pyspark.sql.functions import date_format, asc, countDistinct\n",
    "\n",
    "session_df.withColumn('month', date_format('ts', 'yyyy-MM')).groupby('month').\\\n",
    "    agg(countDistinct(\"userid\").alias(\"mau\")).sort(asc('month')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparkSQL으로 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_session_channel.createOrReplaceTempView(\"user_session_channel\")\n",
    "df_session_timestamp.createOrReplaceTempView(\"session_timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|  channel|uniqueUsers|\n",
      "+---------+-----------+\n",
      "| Facebook|        889|\n",
      "|   Google|        893|\n",
      "|Instagram|        895|\n",
      "|    Naver|        882|\n",
      "|  Organic|        895|\n",
      "|  Youtube|        889|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel_count_df = spark.sql(\"\"\"\n",
    "    SELECT channel, count(distinct userId) uniqueUsers\n",
    "    FROM session_timestamp st\n",
    "    JOIN user_session_channel usc ON st.sessionID = usc.sessionID\n",
    "    GROUP BY 1\n",
    "    ORDER BY 1\"\"\")\n",
    "channel_count_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(month='2019-11', mau=721),\n",
       " Row(month='2019-10', mau=763),\n",
       " Row(month='2019-09', mau=639),\n",
       " Row(month='2019-08', mau=662),\n",
       " Row(month='2019-07', mau=623),\n",
       " Row(month='2019-06', mau=459),\n",
       " Row(month='2019-05', mau=281)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mau_df = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    LEFT(A.ts, 7) AS month,\n",
    "    COUNT(DISTINCT B.userid) AS mau\n",
    "FROM session_timestamp A\n",
    "JOIN user_session_channel B ON A.sessionid = B.sessionid\n",
    "GROUP BY 1\n",
    "ORDER BY 1 DESC\"\"\")\n",
    "mau_df.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
