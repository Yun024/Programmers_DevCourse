{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Python Spark Grouping\") \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .config(\"spark.driver.memory\",\"2g\") \\\n",
    "    .config(\"spark.executor.memory\",\"2g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowflae 연결 정보\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"C:/Users/Yeojun/airflow/airflow-dag/.env\")\n",
    "\n",
    "user = os.environ.get(\"SNOWFLAKE_USER\")\n",
    "password = os.environ.get(\"SNOWFLAKE_PASS\")\n",
    "account = os.environ.get(\"SNOWFLAKE_ACCOUNT\")\n",
    "jdbc_url = f\"jdbc:snowflake://{account}.snowflakecomputing.com/?warehouse=COMPUTE_WH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_session_channel = spark.read \\\n",
    ".format(\"jdbc\")\\\n",
    ".option(\"url\",jdbc_url)\\\n",
    ".option(\"dbtable\",\"dev.raw_data.user_session_channel\")\\\n",
    ".option(\"user\",user)\\\n",
    ".option(\"password\",password)\\\n",
    ".option(\"driver\", \"net.snowflake.client.jdbc.SnowflakeDriver\") \\\n",
    ".load()\n",
    "\n",
    "df_session_timestamp = spark.read \\\n",
    "    .format(\"jdbc\")\\\n",
    "    .option(\"url\",jdbc_url)\\\n",
    "    .option(\"dbtable\",\"dev.raw_data.session_timestamp\")\\\n",
    "    .option(\"user\",user)\\\n",
    "    .option(\"password\",password)\\\n",
    "    .option(\"driver\", \"net.snowflake.client.jdbc.SnowflakeDriver\") \\\n",
    "    .load()\n",
    "\n",
    "df_session_transaction = spark.read \\\n",
    "    .format(\"jdbc\")\\\n",
    "    .option(\"url\",jdbc_url)\\\n",
    "    .option(\"dbtable\",\"dev.raw_data.session_transaction\")\\\n",
    "    .option(\"user\",user)\\\n",
    "    .option(\"password\",password)\\\n",
    "    .option(\"driver\", \"net.snowflake.client.jdbc.SnowflakeDriver\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_session_channel.createOrReplaceTempView(\"user_session_channel\")\n",
    "df_session_timestamp.createOrReplaceTempView(\"session_timestamp\")\n",
    "df_session_transaction.createOrReplaceTempView(\"session_transaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|           SESSIONID|                  TS|\n",
      "+--------------------+--------------------+\n",
      "|7cdace91c487558e2...|2019-05-01 00:13:...|\n",
      "|94f192dee566b018e...|2019-05-01 00:49:...|\n",
      "|7ed2d3454c5eea711...|2019-05-01 10:18:...|\n",
      "|f1daf122cde863010...|2019-05-01 13:10:...|\n",
      "|fd0efcca272f704a7...|2019-05-01 13:45:...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.table(\"session_timestamp\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------+\n",
      "|USERID|           SESSIONID| CHANNEL|\n",
      "+------+--------------------+--------+\n",
      "|   184|c41dd99a69df04044...|   Naver|\n",
      "|    80|fdc0eb412a84fa549...| Organic|\n",
      "|   251|0a54b19a13b6712dc...|Facebook|\n",
      "|   264|a914ecef9c12ffdb9...|  Google|\n",
      "|   744|05ae14d7ae387b933...|Facebook|\n",
      "+------+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_user_session_channel.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JOIN key가 정말 하나씩만 존재하는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|           sessionid|count|\n",
      "+--------------------+-----+\n",
      "|2e907f44e0a961631...|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT sessionid, COUNT(1) count\n",
    "FROM user_session_channel\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "LIMIT 1\"\"\").show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|           sessionid|count|\n",
      "+--------------------+-----+\n",
      "|32bbf7b2bc4ed14eb...|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT sessionid, COUNT(1) count\n",
    "FROM session_timestamp\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "LIMIT 1\"\"\").show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|           sessionid|count|\n",
      "+--------------------+-----+\n",
      "|532ff98823e7d1433...|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT sessionid, COUNT(1) count\n",
    "FROM session_transaction\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "LIMIT 1\"\"\").show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 월별 채널별 총 방문자 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------+\n",
      "|year_month|  channel|total_visitors|\n",
      "+----------+---------+--------------+\n",
      "|   2019-05| Facebook|           247|\n",
      "|   2019-05|   Google|           253|\n",
      "|   2019-05|Instagram|           234|\n",
      "|   2019-05|    Naver|           237|\n",
      "|   2019-05|  Organic|           238|\n",
      "|   2019-05|  Youtube|           244|\n",
      "|   2019-06| Facebook|           414|\n",
      "|   2019-06|   Google|           412|\n",
      "|   2019-06|Instagram|           410|\n",
      "|   2019-06|    Naver|           398|\n",
      "|   2019-06|  Organic|           416|\n",
      "|   2019-06|  Youtube|           400|\n",
      "|   2019-07| Facebook|           558|\n",
      "|   2019-07|   Google|           556|\n",
      "|   2019-07|Instagram|           567|\n",
      "|   2019-07|    Naver|           553|\n",
      "|   2019-07|  Organic|           557|\n",
      "|   2019-07|  Youtube|           564|\n",
      "|   2019-08| Facebook|           611|\n",
      "|   2019-08|   Google|           610|\n",
      "+----------+---------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mon_channel_rev_df = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        LEFT(sti.ts, 7) year_month,\n",
    "        usc.channel channel,\n",
    "        COUNT(DISTINCT userid) total_visitors\n",
    "    FROM user_session_channel usc\n",
    "    LEFT JOIN session_timestamp sti ON usc.sessionid = sti.sessionid\n",
    "    GROUP BY 1 ,2\n",
    "    ORDER BY 1, 2\"\"\")\n",
    "mon_channel_rev_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 월별 채널별 총 방문자와 구매 방문자 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------+-------------+\n",
      "|year_month|  channel|total_visitors|paid_visitors|\n",
      "+----------+---------+--------------+-------------+\n",
      "|   2019-05| Facebook|           247|           14|\n",
      "|   2019-05|   Google|           253|           10|\n",
      "|   2019-05|Instagram|           234|           11|\n",
      "|   2019-05|    Naver|           237|           11|\n",
      "|   2019-05|  Organic|           238|           17|\n",
      "|   2019-05|  Youtube|           244|           10|\n",
      "|   2019-06| Facebook|           414|           22|\n",
      "|   2019-06|   Google|           412|           13|\n",
      "|   2019-06|Instagram|           410|           21|\n",
      "|   2019-06|    Naver|           398|           15|\n",
      "|   2019-06|  Organic|           416|           14|\n",
      "|   2019-06|  Youtube|           400|           17|\n",
      "|   2019-07| Facebook|           558|           32|\n",
      "|   2019-07|   Google|           556|           21|\n",
      "|   2019-07|Instagram|           567|           25|\n",
      "|   2019-07|    Naver|           553|           19|\n",
      "|   2019-07|  Organic|           557|           24|\n",
      "|   2019-07|  Youtube|           564|           36|\n",
      "|   2019-08| Facebook|           611|           18|\n",
      "|   2019-08|   Google|           610|           28|\n",
      "+----------+---------+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mon_channel_rev_df = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        LEFT(sti.ts, 7) year_month,\n",
    "        usc.channel channel,\n",
    "        COUNT(DISTINCT userid) total_visitors,\n",
    "        COUNT(DISTINCT CASE WHEN amount is not NULL THEN userid END) paid_visitors\n",
    "    FROM user_session_channel usc\n",
    "    LEFT JOIN session_timestamp sti ON usc.sessionid = sti.sessionid\n",
    "    LEFT JOIN session_transaction str ON usc.sessionid = str.sessionid\n",
    "    GROUP BY 1 ,2\n",
    "    ORDER BY 1, 2\"\"\")\n",
    "\n",
    "mon_channel_rev_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 월별 채널별 총 매출액 (리펀드 포함), 총 방문자, 매출 발생 방문자, 전환률 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+---------+------------+----------+--------------+\n",
      "|  month|  channel|uniqueUsers|paidUsers|grossRevenue|netRevenue|conversionRate|\n",
      "+-------+---------+-----------+---------+------------+----------+--------------+\n",
      "|2019-05| Facebook|        247|       14|        1199|       997|          5.67|\n",
      "|2019-05|   Google|        253|       10|         580|       580|          3.95|\n",
      "|2019-05|Instagram|        234|       11|         959|       770|           4.7|\n",
      "|2019-05|    Naver|        237|       11|         867|       844|          4.64|\n",
      "|2019-05|  Organic|        238|       17|        1846|      1571|          7.14|\n",
      "|2019-05|  Youtube|        244|       10|         529|       529|           4.1|\n",
      "|2019-06| Facebook|        414|       22|        1578|      1578|          5.31|\n",
      "|2019-06|   Google|        412|       13|         947|       947|          3.16|\n",
      "|2019-06|Instagram|        410|       21|        1462|      1418|          5.12|\n",
      "|2019-06|    Naver|        398|       15|        1090|      1090|          3.77|\n",
      "|2019-06|  Organic|        416|       14|        1129|       940|          3.37|\n",
      "|2019-06|  Youtube|        400|       17|        1042|      1042|          4.25|\n",
      "|2019-07| Facebook|        558|       32|        2222|      2144|          5.73|\n",
      "|2019-07|   Google|        556|       21|        1558|      1385|          3.78|\n",
      "|2019-07|Instagram|        567|       25|        1896|      1766|          4.41|\n",
      "|2019-07|    Naver|        553|       19|        1547|      1547|          3.44|\n",
      "|2019-07|  Organic|        557|       24|        1600|      1600|          4.31|\n",
      "|2019-07|  Youtube|        564|       36|        2210|      2037|          6.38|\n",
      "|2019-08| Facebook|        611|       18|        1009|      1009|          2.95|\n",
      "|2019-08|   Google|        610|       28|        2210|      1894|          4.59|\n",
      "+-------+---------+-----------+---------+------------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mon_channel_rev_df = spark.sql(\"\"\"\n",
    "SELECT LEFT(ts, 7) month,\n",
    "    usc.channel,\n",
    "    COUNT(DISTINCT userid) uniqueUsers,\n",
    "    COUNT(DISTINCT (CASE WHEN amount >= 0 THEN userid END)) paidUsers,\n",
    "    SUM(amount) grossRevenue,\n",
    "    SUM(CASE WHEN refunded is not True THEN amount END) netRevenue,\n",
    "    ROUND(COUNT(DISTINCT CASE WHEN amount >= 0 THEN userid END)*100\n",
    "        / COUNT(DISTINCT userid), 2) conversionRate\n",
    "FROM user_session_channel usc\n",
    "LEFT JOIN session_timestamp t ON t.sessionid = usc.sessionid\n",
    "LEFT JOIN session_transaction st ON st.sessionid = usc.sessionid\n",
    "GROUP BY 1, 2\n",
    "ORDER BY 1, 2;\n",
    "\"\"\")\n",
    "\n",
    "mon_channel_rev_df.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
