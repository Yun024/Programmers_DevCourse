{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Python Spark Ranking\") \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .config(\"spark.driver.memory\",\"2g\") \\\n",
    "    .config(\"spark.executor.memory\",\"2g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowflae 연결 정보\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"C:/Users/Yeojun/airflow/airflow-dag/.env\")\n",
    "\n",
    "user = os.environ.get(\"SNOWFLAKE_USER\")\n",
    "password = os.environ.get(\"SNOWFLAKE_PASS\")\n",
    "account = os.environ.get(\"SNOWFLAKE_ACCOUNT\")\n",
    "jdbc_url = f\"jdbc:snowflake://{account}.snowflakecomputing.com/?warehouse=COMPUTE_WH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_session_channel = spark.read \\\n",
    ".format(\"jdbc\")\\\n",
    ".option(\"url\",jdbc_url)\\\n",
    ".option(\"dbtable\",\"dev.raw_data.user_session_channel\")\\\n",
    ".option(\"user\",user)\\\n",
    ".option(\"password\",password)\\\n",
    ".option(\"driver\", \"net.snowflake.client.jdbc.SnowflakeDriver\") \\\n",
    ".load()\n",
    "\n",
    "df_session_timestamp = spark.read \\\n",
    "    .format(\"jdbc\")\\\n",
    "    .option(\"url\",jdbc_url)\\\n",
    "    .option(\"dbtable\",\"dev.raw_data.session_timestamp\")\\\n",
    "    .option(\"user\",user)\\\n",
    "    .option(\"password\",password)\\\n",
    "    .option(\"driver\", \"net.snowflake.client.jdbc.SnowflakeDriver\") \\\n",
    "    .load()\n",
    "\n",
    "df_session_transaction = spark.read \\\n",
    "    .format(\"jdbc\")\\\n",
    "    .option(\"url\",jdbc_url)\\\n",
    "    .option(\"dbtable\",\"dev.raw_data.session_transaction\")\\\n",
    "    .option(\"user\",user)\\\n",
    "    .option(\"password\",password)\\\n",
    "    .option(\"driver\", \"net.snowflake.client.jdbc.SnowflakeDriver\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_session_channel.createOrReplaceTempView(\"user_session_channel\")\n",
    "df_session_timestamp.createOrReplaceTempView(\"session_timestamp\")\n",
    "df_session_transaction.createOrReplaceTempView(\"session_transaction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 총 매출이 가장 많은 사용자 10명 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_rev_user_df = spark.sql(\"\"\"\n",
    "SELECT userid,\n",
    "SUM(str.amount) revenue,\n",
    "SUM(CASE WHEN str.refunded = False THEN str.amount END) net_revenue\n",
    "FROM user_session_channel usc\n",
    "JOIN session_transaction str ON usc.sessionid = str.sessionid\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "LIMIT 10\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----------+\n",
      "|userid|revenue|net_revenue|\n",
      "+------+-------+-----------+\n",
      "|   989|    743|        743|\n",
      "|   772|    556|        556|\n",
      "|  1615|    506|        506|\n",
      "|   654|    488|        488|\n",
      "|  1651|    463|        463|\n",
      "|   973|    438|        438|\n",
      "|   262|    422|        422|\n",
      "|  1099|    421|        343|\n",
      "|  2682|    414|        414|\n",
      "|   891|    412|        412|\n",
      "+------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_rev_user_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_rev_user_df2 = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    userid,\n",
    "    SUM(st.amount) total_amount,\n",
    "    RANK() OVER (ORDER BY SUM(st.amount) DESC) rank\n",
    "FROM user_session_channel usc\n",
    "JOIN session_transaction st ON usc.sessionid = st.sessionid\n",
    "GROUP BY 1\n",
    "ORDER BY rank\n",
    "LIMIT 10\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+----+\n",
      "|userid|total_amount|rank|\n",
      "+------+------------+----+\n",
      "|   989|         743|   1|\n",
      "|   772|         556|   2|\n",
      "|  1615|         506|   3|\n",
      "|   654|         488|   4|\n",
      "|  1651|         463|   5|\n",
      "|   973|         438|   6|\n",
      "|   262|         422|   7|\n",
      "|  1099|         421|   8|\n",
      "|  2682|         414|   9|\n",
      "|   891|         412|  10|\n",
      "+------+------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_rev_user_df2.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
